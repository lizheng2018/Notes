## LightGBM算法

### 介绍



![img](https://www.biaodianfu.com/wp-content/uploads/2019/03/lightgbm.png)

### 主要特点

* 带深度限制的Leaf-wise的叶子生长策略
* 基于Histogram的决策树算法
* Histogram图做差加速
* 直接支持类别特征(Categorical Feature)
* Cache命中率优化
* 基于直方图的稀疏特征优化
* 多线程优化

### 2.树生成原理

#### 2.1 Level (depth)-wise

大多数树的生产原理如下： **level (depth)-wise**，按层生长。同一层的所有节点都做分裂，最后剪枝。

![img](https://lightgbm.readthedocs.io/en/latest/_images/level-wise.png)

**优点**：容易多线程优化，好控制模型复杂度，不容易过拟合

**缺点**：比较低效，很多叶子的分裂增益Gain较低，没必要进行搜索和分裂

#### 2.2 Leaf-wise

LightGBM采用的是**Leaf**-wise tree growth, 每次从当前所有叶子中，找到分裂增益最大的一个叶子，然后分裂，如此循环。

![img](https://lightgbm.readthedocs.io/en/latest/_images/leaf-wise.png)

**优点**：同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度

**缺点**：可能会长出比较深的决策树，产生过拟合。因此LightGBM在Leaf-wise之上增加了一个最大深度的限制max_depth，在保证高效率的同时防止过拟合

### 3.Histogram直方图算法原理

把连续的浮点特征值离散化成k个整数，同时构造一个宽度为k的直方图(bin)。一个区间的范围内作为一个bin，数据的表示更加简化，减少了内存的适用，而且直方图带来了一定的正则化的效果，不易过拟合。在遍历数据的时候，根据离散化后的值生成索引在直方图中累积统计量，当遍历一次数据后，根据直方图的离散值，遍历寻找最优的分割点。

![img](https://fuhailin.github.io/LightGBM/20181126165335641.png)

Histogram优化原理：

![img](https://fuhailin.github.io/LightGBM/20181126164828201.jpg)

1. **`For all Leaf p in Tc-1(X)`**: 表示循环当前树下所有的叶子节点
2. **`For all f in X.Features`**: 开始遍历某个叶子上所有的特征，比如从100特征中找出最佳分裂特征
3. **`For i in(0, num_of_row)`**: 开始遍历所有的样本来构建直方图（样本装箱），直方图的每个 bin 中包含了一定的样本，在此计算每个 bin 中的样本的梯度之和并对 bin 中的样本记数

> 其中`f.bins[i]`为特征`f`在样本`i`的对应bin；`H[f.bins[i]]`则表示对bin进行累加，该bin就是特征`f`在样本`i`的对应bin

4. **`For i in(0, len(H))`**：开始遍历所有的 bin，找到适合分裂的最佳 bin

SL是当前分裂 bin 左边所有 bin 的集合，对比理解SR，那么SP其中的 P 就是 parent 的意思，就是父节点，传统的决策树会有分裂前后信息增益的计算，典型的 ID3 或者 C45 之类，在这里我们也会计算，但是 SR 中所有 bin 的梯度之和不需要在额外计算了，直接使用父节点的减去左边的就得到。

公式的中 loss 就是来衡量分裂的好坏的，在遍历完所有的特征之后根据 loss，理论上 loss 最小的特征会被选中作为最佳的分裂节点。

**优点**：

1. 内存消耗的降低，pre-sorted算法需要保存起来每一个特征的排序结构，所以其需要的内存大小是：

    （2 * #data * #feature * 4Bytes），如下图

    ![img](https://fuhailin.github.io/LightGBM/20181126170048718.png)

2. 计算效率提高，pre-sorted算法需要对每个特征下样本都遍历一遍，并计算增益，复杂度为O(#feature * #data)。而直方图算法在建立完直方图后，只需要对每个特征遍历直方图即可，复杂度为O(#feature * #bins)

3. 数据并行时，直方图算法可以**大幅降低通信代价**

**缺点**：

1. 特征被离散化后（装箱），不能精确分割样本
2. 直方图不能对稀疏样本进行优化，只是计算累加值（累加梯度和样本数），但是，LightGBM 对稀疏进行了优化：**只用非零特征构建直方图**。

**注意**：

* 虽然直方图分割后精度变差，但是对最后结果的影响不是很大，主要由于基模型是决策树，分割点是不是精确并不是太重要 
* 较粗的分割点也有正则化的效果，可以有效地防止过拟合
* 即使单棵树的训练误差比精确分割的算法稍大，但在梯度提升（Gradient Boosting）的框架下没有太大的影响。

#### 3.1 Histogram差加速

![1554723182923](C:\Users\MarioCode\AppData\Roaming\Typora\typora-user-images\1554723182923.png)

一个叶子的直方图可以由它的父节点的直方图与它兄弟的直方图做差得到，计算速度可以提升约一倍

3.2 Histogram算法两大改进









​    

###  XGBoost

pre-sorted算法，能够更精确的找到数据分隔点。

* 对所有特征按数值进行预排序
* 在每次的样本分割时，用O(# data)的代价找到每个特征的最优分割点，即对整个数据集进行特征样本分割，代价巨大
* 最后，找到最后的特征以及分割点，将数据分裂成左右两个子节点。

这种pre-sorting算法能够准确找到分裂点，但是在空间和时间上有很大的开销。

* 由于需要对特征进行预排序并且需要保存排序后的索引值（为了后续快速的计算分裂点），因此内存需要训练数据的两倍。
* 在遍历每一个分割点的时候，都需要进行分裂增益的计算，消耗的代价大。





### 参数设置


|     特点     | XGBoost                                                      |                         LightGBM                          |
| :----------: | :----------------------------------------------------------- | :-------------------------------------------------------: |
|  树生长算法  |                                                              |                                                           |
| 数据分割方法 | pre-sorted算法，能够更精确的找到数据分隔点<br/>1. 对所有特征按数值进行预排序<br />2. 在每次的样本分割时，用O(# data)的代价找到每个特征的最优分割点<br />3. 找到最后的特征以及分割点，将数据分裂成左右两个子节点 | **histogram算法**，占用的内存更低，数据分隔的复杂度更低。 |
|  时间复杂度  |                                                              |                                                           |
|              |                                                              |                                                           |




### 使用实例





