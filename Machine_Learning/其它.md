## 其它

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

### 目标函数

$$
Obj(\Theta)=L(\Theta)+\Omega(\Theta)
$$

其中，$L(\Theta)$ 是损失函数，用来衡量模型拟合训练数据的好坏程度；$\Omega(\Theta)$称之为正则项，用来衡量学习到的模型的复杂度。训练集上的损失（Loss）定义为：$L=\sum_{i=1}^n l(y_i, \hat{y}_i)$。

常用的损失函数有平方损失（square loss）：$l(y_i, \hat{y}_i)=(y_i - \hat{y}_i)^2$ 

Logistic损失： $l(y_i, \hat{y}_i)=y_i ln(1+e^{y_i}) + (1-y_i)ln(1+e^{\hat{y}_i})$

常用的正则项有L1范数$\Omega(w)=\lambda \Vert w \Vert_1$和L2范数$\Omega(w)=\lambda \Vert w \Vert_2$

* Ridge regression就是指使用平方损失和L2范数正则项的线性回归模型

* Lasso regression就是指使用平方损失和L1范数正则项的线性回归模型

* 逻辑回归（Logistic regression）指使用logistic损失和L2范数或L1范数正则项的线性模型










