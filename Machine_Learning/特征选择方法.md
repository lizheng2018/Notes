## 特征选择

几个概念：

方差分析（ANOVA），analysis of variance



### 1. F值和 P-value

scikit-learn中的公式：

第一步：求出ri

![1555052528060](C:\Users\MarioCode\AppData\Roaming\Typora\typora-user-images\1555052528060.png)

Xi是代表所有样本的在i号特征上的取值的n维列向量，分子上其实两个n维列向量的内积，所以ri是一个**数值**，其实就是样本相关系数

第二步：利用ri求出f值

![1555053013370](C:\Users\MarioCode\AppData\Roaming\Typora\typora-user-images\1555053209938.png)

上式才是f_regression中的f值，服从F(1,n−2)分布，f值越大，Xi特征和因变量y之间的相关性就越大

第三步：f_regression还有一个返回值p-value，这个p-value就是用于检验特征与变量之间相关性的，假设你给出α值（常取0.05，0.01），如果你的p-value小于α，那就有把握认为，这个特征和预测变量y之间，具有相关性。比方说你取α=0.05，这就意味着你有95%（也就是1-α）的把握认为，这个特征和预测变量y之间存在相关性

```python
from sklearn.feature_selection import f_regression

X = np.random.rand(1000, 3)
y = X[:, 0] + np.sin(6 * np.pi * X[:, 1]) + 0.1 * np.random.randn(1000)

f_test, p_value= f_regression(X, y)

```










